<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>切梦刀</title>
  
  <subtitle>岁月是把切梦刀</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://litstockz.github.io/"/>
  <updated>2019-03-21T13:24:45.373Z</updated>
  <id>https://litstockz.github.io/</id>
  
  <author>
    <name>litstockz</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>西瓜书总结</title>
    <link href="https://litstockz.github.io/2019/03/01/%E8%A5%BF%E7%93%9C%E4%B9%A6/"/>
    <id>https://litstockz.github.io/2019/03/01/西瓜书/</id>
    <published>2019-03-01T13:23:08.000Z</published>
    <updated>2019-03-21T13:24:45.373Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>我的西瓜书学习路径和总结<br><a id="more"></a></p><h2 id="学习路线"><a href="#学习路线" class="headerlink" title="学习路线"></a>学习路线</h2><ol><li>第一章-绪论</li><li>第三章-线性模型</li><li>第四章-决策树</li><li>第六章-支持向量机</li><li>第七章-贝叶斯分类器</li><li>第五章-神经网络</li><li>第二章-模型评估与选择</li><li>第10、11章- 特征选择/特征提取</li><li>第八章-集成学习</li><li>第九章-聚类</li><li>第十四章-概率图模型</li></ol><hr><h2 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章-绪论"></a>第一章-绪论</h2><h3 id="学习导图"><a href="#学习导图" class="headerlink" title="学习导图"></a>学习导图</h3><ul><li>监督学习(Supervised Learning)<ul><li>回归问题Regression ：输出数值</li><li>分类问题Classification ：预测二分类，多分类问题<ul><li>线性模型</li><li>非线性模型<ul><li>深度学习</li><li>支持向量机SVM</li><li>决策树</li><li>邻近算法K-NN</li><li>…</li></ul></li></ul></li><li>结构化问题Structured Learning<ul><li>在实际运用中，常常会遇到Beyond Classification的情况，比如语音识别，人脸识别，语言翻译等，是结构化输出。此类问题常合Reinforcement Learning 解决</li></ul></li></ul></li><li>半监督学习</li><li>迁移学习</li><li>无监督学习</li><li>强化学习Reinforcement Learning<ul><li>思考：监督学习和强化学习的区别</li></ul></li></ul><h3 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h3><ul><li>定义：机器学习是致力于通过计算的手段，利用数据来改善系统自身的性能的学科</li><li>研究内容：从数据中产生“模型”的算法（即学习算法）</li><li>如何运用：有了学习算法，将经验数据传给学习算法后，产生相应模型；在面对新情况时，模型将会给出相应的判断。</li></ul><h3 id="2-基本术语"><a href="#2-基本术语" class="headerlink" title="2. 基本术语"></a>2. 基本术语</h3><ul><li><p>属性：反映事件或对象在某方面的表现或性质的事项。例如每条记录中的“色泽”、“根蒂”、“敲声”就是西瓜的属性</p></li><li><p>属性空间：属性张成的空间。例如我们把”色泽” “根蒂” “敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间就是属性空间</p></li><li><p>特征向量：每个西瓜都可在这个空间中找到自己的坐标位置。由于空间中的每个点对应一个坐标向量，因此我们也把这个坐标向量称为一个特征向量。</p></li><li><p>三者的关系总结：将每个属性作为一个坐标轴，多个属性就多个坐标轴，从而形成一个描述物体的属性空间。此空间中的每个样本对应一个点，每个点都有一个坐标向量，把这个坐标向量称为特征向量。</p></li><li><p>如果希望学得一个能帮助我们判断没剖开的是不是”好瓜”的模型，仅有前面的示例数据显然是不够的要建立这样的关于”预测” 的模型，我们还需获得训练样本的”结果”信息，例如”((色泽=青绿;根蒂=蜷缩;敲声=浊响)，好瓜)” 。</p></li><li><p>标记：关于示例结果的信息，比如上面例子中的 “好瓜” 就属于标记。</p></li><li><p>样例：拥有了标记信息的示例，则称为样例。</p></li><li><p>机器学习的目标是希望通过对训练集  进行学习，建立一个从输入空间 X 到输出空间 Y 的映射</p><p>根据预测结果的类型，可以将机器学习任务分为二类。</p><ul><li>分类：预测结果的类型是离散值，例如”好瓜”，”坏瓜”；</li><li>回归：预测结果的类型是连续值，例如西瓜的成熟度0.37、0.95。</li></ul><p>根据训练数据是否拥有标记信息，学习任务也可大致划分为两大类。</p><ul><li>监督学习(supervised learning)：训练数据有标记信息，其中分类与回归属于监督学习。</li><li>无监督学习(unsupervised learning)：训练数据没有标记信息，代表有聚类。</li></ul></li></ul><h3 id="3-假设空间"><a href="#3-假设空间" class="headerlink" title="3. 假设空间"></a>3. 假设空间</h3><ul><li>假设空间：所有假设构成的集合。</li><li>版本空间：只保留了假设空间中与训练数据集中正例一致的假设，由这些正确的假设构成的集合成为版本空间（简单来说，版本空间就是正例的泛化）。</li><li><p>版本空间构建过程：首先对假设空间进行搜索。有许多策略对假设空间搜索，如自顶向下和自底向上。然后在搜索过程中只保留与训练集正例一致的假设。比如搜索到（色泽=青绿，根蒂=蜷缩，敲声=浊响）这个假设时，它本身与训练集第 1 条正例一致，但是与训练集中第 2 条正例不一致，所以需要剔除。因为若这个假设保留到版本空间且根据版本空间的定义，说明色泽非青绿，根蒂非蜷缩，敲声非浊响的瓜都为坏瓜，这与表中第 2 条正例相矛盾。再比如搜索到（色泽=<em>，根蒂=</em>，敲声=浊响）这个假设可以保留到版本空间，因为当它成立时，我们可以对于表中的4个训练示例都做出正确的判断，即它与训练集的所有正例一致。最后在上面训练集构建的版本空间如图。<br><img src="https://animeplant-1256206995.cos.ap-guangzhou.myqcloud.com/xigua1.png" alt="版本空间.jpg"></p></li><li><p>版本空间作用除了能对已知的数据样本做出判断外，版本空间还可以对没有在训练集中出现的示例进行判断。如给一个（色泽=浅白) ⋀ (根蒂=蜷缩) ⋀ (敲声=浊晌) 瓜，通过版本空间判断它是好瓜。</p></li><li>最后，上面求出来了西瓜问题的版本空间，但可以看到版本空间不是很确定，包含有通配符 * 的假设可能会得到正确的判断，也可能得到错误的判断（这句话是针对实际问题，如果针对上表中的训练集，那当然不会有错误的判断）</li><li>因此，要想判断的正确，就要全面、大量的训练，以排除更多假设空间中的错误假设。错误假设越少，剩下的假设越少，就越有可能是正确假设，我们判断的结果的正确概率越大。</li></ul><h3 id="4-归纳偏好"><a href="#4-归纳偏好" class="headerlink" title="4. 归纳偏好"></a>4. 归纳偏好</h3><ul><li>从假设空间到版本空间是一个归纳过程（即从特殊到一般的过程）。</li><li>现在有一个问题，例如（色泽=青绿，根蒂=蜷缩，敲声=沉闷）这新瓜，如果采用(色泽=<em>) ⋀ (根蒂=蜷缩) ⋀ (敲声=</em>)这个假设进行判断，这新瓜就是好瓜；但是采用（色泽=<em>) ⋀ (根蒂=</em>) ⋀ (敲声=浊响)这个假设判断，这新瓜就是坏瓜。那么，应该采用哪一个模型(或假设)呢？若仅有上表中的训练样本，则无法断定上述三个假设中明哪一个”更好”.然而，对于一个具体的学习算法而言？它必须要产生一个模型。这时，学习算法本身的”偏好”就会起到关键的作用。</li><li>归纳偏好(简称”偏好”)：机器学习算法在学习过程中对某种类型假设的偏好。</li><li>任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上”等效”的假设所迷惑，无法产生确定的学习结果。如果没有偏好，刚才那个例子就没有确定的答案了。这样的学习结果显得没有意义。</li><li>最后，算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。</li></ul><hr><h2 id="第三章-线性模型"><a href="#第三章-线性模型" class="headerlink" title="第三章-线性模型"></a>第三章-线性模型</h2><p>这部分就是本书的第一个机器学习模型，线性模型，一个简单而重要的模型，前两节主要讲线性回归，主要是最小二乘法的内容，相信大家都不陌生的。而第三小节讲的对数几率回归才是这章的核心，这个算法也是目前应用最广的算法之一。</p><h3 id="1-基本形式"><a href="#1-基本形式" class="headerlink" title="1.基本形式"></a>1.基本形式</h3><p><img src="https://animeplant-1256206995.cos.ap-guangzhou.myqcloud.com/d57552000503bd3c5660409268531c3.jpg" alt="基本形式"></p><p>由于w直观表达了各属性在预测中的重要性，因此此模型有很好的可解释性（可理解性）</p><h3 id="2-线性回归"><a href="#2-线性回归" class="headerlink" title="2.线性回归"></a>2.线性回归</h3><p>均方误差是回归任务中最常用的度量。<br>线性回归推导见笔记。</p><h3 id="3-对数几率回归-逻辑回归"><a href="#3-对数几率回归-逻辑回归" class="headerlink" title="3.对数几率回归(逻辑回归)"></a>3.对数几率回归(逻辑回归)</h3><p>如何使用线性回归进行分类任务：只需找一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来。</p><p>极大似然可以直接推导出损失函数（min） (min cross Entropy)<br>推导过程见笔记。</p><p>逻辑回归是一种分类学习方法，它的优点：</p><ul><li>它是直接对分类可能性进行建模，无需实现假设数据分布，这样就避免了假设分布不准确所带来的问题</li><li>它不仅预测出“类别”，而是可得到近似概率预测，这对许多需利用概率辅助决策的任务很有用</li><li>逻辑函数是任意阶可导的凸函数，有很好的数学性质，现有的许多数值优化算法都可直接用于求取最优解。</li></ul><h3 id="4-线性判别法"><a href="#4-线性判别法" class="headerlink" title="4.线性判别法"></a>4.线性判别法</h3><h3 id="5-多分类学习"><a href="#5-多分类学习" class="headerlink" title="5.多分类学习"></a>5.多分类学习</h3><hr><h2 id="第四章-决策树"><a href="#第四章-决策树" class="headerlink" title="第四章-决策树"></a>第四章-决策树</h2><h3 id="1-基本流程"><a href="#1-基本流程" class="headerlink" title="1.基本流程"></a>1.基本流程</h3><p>面对一个实际的数据集，应该如何构建出一颗树？</p><h3 id="2-划分选择"><a href="#2-划分选择" class="headerlink" title="2.划分选择"></a>2.划分选择</h3><hr><h2 id="第六章-支持向量机"><a href="#第六章-支持向量机" class="headerlink" title="第六章-支持向量机"></a>第六章-支持向量机</h2><hr><h2 id="第七章-贝叶斯分类器"><a href="#第七章-贝叶斯分类器" class="headerlink" title="第七章-贝叶斯分类器"></a>第七章-贝叶斯分类器</h2><hr><h2 id="第五章-神经网络"><a href="#第五章-神经网络" class="headerlink" title="第五章-神经网络"></a>第五章-神经网络</h2><hr><h2 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章-模型评估与选择"></a>第二章-模型评估与选择</h2><hr><h2 id="第10、11章-特征选择-特征提取"><a href="#第10、11章-特征选择-特征提取" class="headerlink" title="第10、11章- 特征选择/特征提取"></a>第10、11章- 特征选择/特征提取</h2><hr><h2 id="第八章-集成学习"><a href="#第八章-集成学习" class="headerlink" title="第八章-集成学习"></a>第八章-集成学习</h2><hr><h2 id="第九章-聚类"><a href="#第九章-聚类" class="headerlink" title="第九章-聚类"></a>第九章-聚类</h2><hr><h2 id="第十四章-概率图模型"><a href="#第十四章-概率图模型" class="headerlink" title="第十四章-概率图模型"></a>第十四章-概率图模型</h2><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我的西瓜书学习路径和总结&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
